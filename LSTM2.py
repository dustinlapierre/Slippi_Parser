from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.layers import Embedding
from keras.layers import LSTM
import numpy as np

#define melee data set
#using a fake for now
#what do I do here????
x = [
[100, 0, 20, -31.948753356933594, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[101, 0, 20, -33.98875427246094, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[102, 0, 20, -35.948753356933594, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[103, 0, 20, -37.82875442504883, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[104, 0, 20, -39.628753662109375, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[105, 0, 20, -41.3487548828125, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[106, 0, 20, -42.98875427246094, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[107, 0, 18, -43.318756103515625, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[108, 0, 20, -43.64875793457031, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[109, 0, 20, -41.95875930786133, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[110, 0, 20, -40.14875793457031, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[111, 0, 20, -38.21875762939453, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[112, 0, 20, -36.168758392333984, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[113, 0, 20, -34.19875717163086, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[114, 0, 18, -33.786258697509766, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[115, 0, 20, -33.37376022338867, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[116, 0, 20, -34.981258392333984, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[117, 0, 20, -36.70875930786133, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[118, 0, 20, -38.55625915527344, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[119, 0, 20, -40.52375793457031, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[120, 0, 20, -42.61125946044922, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[121, 0, 20, -44.81126022338867, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[122, 0, 20, -47.011260986328125, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[123, 0, 20, -49.13125991821289, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[124, 0, 20, -51.171260833740234, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[125, 0, 18, -51.601261138916016, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[126, 0, 20, -52.0312614440918, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[127, 0, 20, -50.441261291503906, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[128, 0, 20, -48.73126220703125, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 57, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[129, 0, 20, -46.90126037597656, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 41, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[130, 0, 20, -44.95125961303711, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 41, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[131, 0, 20, -42.88125991821289, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 41, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[132, 0, 20, -40.691261291503906, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 41, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[133, 0, 20, -38.581260681152344, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 41, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[134, 0, 18, -38.13376235961914, 9.999999747378752e-05, 1.0, 0.0, 60.0, 4, 1, 41, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[135, 0, 20, -37.68626403808594, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 41, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[136, 0, 20, -39.25876235961914, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 41, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[137, 0, 20, -40.951263427734375, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 41, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[138, 0, 20, -42.763763427734375, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 41, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[139, 0, 20, -44.69626235961914, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 14, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[140, 0, 20, -46.74876403808594, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 14, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[141, 0, 20, -48.9212646484375, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 14, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4],
[142, 0, 20, -51.12126541137695, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4, 1, 14, 9.651655197143555, 9.999999747378752e-05, -1.0, 0.0, 60.0, 4]
]

#define model
#16 melee input numbers so the input dim is 16xnumber of sequences?
model = Sequential()
model.add(Embedding(max_features, output_dim=256))
model.add(LSTM(128))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

# Compile model
model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

# Fit the model
model.fit(x_train, y_train, batch_size=16, epochs=10)
score = model.evaluate(x_test, y_test, batch_size=16)
print(score)
